{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "source": [
    "## Yolo11 tests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os , sys\n",
    "import shutil\n",
    "from tqdm.auto import tqdm  \n",
    "sys.path.append('..')\n",
    "from pathlib import Path\n",
    "cur_path = Path(os.getcwd()).parent\n",
    "sam2_path = cur_path / 'sam2_octron'\n",
    "sys.path.append(cur_path.as_posix())\n",
    "from matplotlib import pyplot as plt\n",
    "import cmasher as cmr\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "sns.set_theme(style='white')\n",
    "%config InlineBackend.figure_format = 'retina'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from napari_pyav._reader import FastVideoReader\n",
    "from octron.sam2_octron.helpers.video_loader import probe_video\n",
    "from octron.yolo_octron.helpers.training import (load_object_organizer, \n",
    "                                                 collect_labels, \n",
    "                                                 draw_polygons,\n",
    "                                                 train_test_val,\n",
    "                                                 write_training_data,\n",
    "                                                 write_yolo_config_yaml,\n",
    "                                                 \n",
    ")\n",
    "from octron.sam2_octron.helpers.sam2_zarr import load_image_zarr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Presaved model (YOLOv11)\n",
    "path_to_model = Path('/Users/horst/Documents/python/OCTRON/octron/yolo_octron/yolo11l-seg.pt')\n",
    "project_path = Path('/Users/horst/Downloads/octron_project_2')\n",
    "assert project_path.exists()\n",
    "assert path_to_model.exists()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from zarr.core import array # For type checking "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Find out what info is present across object organizers / ..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Construct a nice loop that finds the zarr, video files, and compares video file hashes \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract info from project path \n",
    "for object_organizer in project_path.rglob('object_organizer.json'):\n",
    "    print(object_organizer.parent)\n",
    "    organizer_dict = load_object_organizer(object_organizer)  \n",
    "    labels = {}\n",
    "    for entry in organizer_dict['entries'].values():\n",
    "        pass\n",
    "        # label_id = int(entry['label_id'] )\n",
    "        # label    = entry['label'] \n",
    "        # color    = entry['color']\n",
    "        # if label_id in labels:\n",
    "        #     assert labels[label_id]['label'] == label, 'Label name vs. id do not match'\n",
    "        # else:\n",
    "        #     # First time we see this label\n",
    "        #     labels[label_id] = {'label':label, \n",
    "        #                         'frames': [],\n",
    "        #                         'masks': [], \n",
    "        #                         'color': color, # Only save the first color\n",
    "        #                         }   \n",
    "\n",
    "        # # Find out which frames were annotated\n",
    "        # zarr_path_relative = Path(entry['prediction_layer_metadata']['zarr_path'])\n",
    "        # zarr_path = project_path / zarr_path_relative\n",
    "        # assert zarr_path.exists(), f'Zarr file not found at {zarr_path}'\n",
    "        # num_frames, image_height, image_width = entry['prediction_layer_metadata']['data_shape']\n",
    "        # loaded_masks, status = load_image_zarr(zarr_path, \n",
    "        #                             num_frames,\n",
    "        #                             image_height, \n",
    "        #                             image_width, \n",
    "        #                             num_ch=None,\n",
    "        #                             verbose=False,\n",
    "        #                             ) # Not doing hash comparison here! \n",
    "        # assert status == True\n",
    "        # assert loaded_masks is not None\n",
    "        # assert isinstance(loaded_masks, array.Array), f'Expected zarr array for masks, got {type(loaded_masks)}'\n",
    "        \n",
    "        # # Comparisons\n",
    "        # # Make sure information is consistent across object organizer (json)\n",
    "        # # and zarr array data \n",
    "        # assert num_frames == loaded_masks.shape[0]\n",
    "        # assert image_height == loaded_masks.shape[1]\n",
    "        # assert image_width == loaded_masks.shape[2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Video reader \n",
    "# video_dict = probe_video(path_to_video)\n",
    "# video_data = FastVideoReader(path_to_video)  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Process training data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# organizer_dict = load_object_organizer(path_to_json_organizer)  \n",
    "# assert organizer_dict is not None\n",
    "# labels = collect_labels(organizer_dict,\n",
    "#                         )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#draw_polygons(labels, video_data, 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Perform the split of the data\n",
    "# # .. 80% training, 10% validation and 10% testing\n",
    "# print('Splitting the data for training into training, validation and testing fractions')  \n",
    "# for label_id, label_dict in labels.items():\n",
    "#     print(label_dict['label'])\n",
    "#     label_split = train_test_val(label_dict['frames'], \n",
    "#                                  training_fraction=0.8,\n",
    "#                                  validation_fraction=0.1,\n",
    "#                                  verbose=True)\n",
    "#     labels[label_id]['frames_split'] = label_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Now export the data to the respective directories\n",
    "# # We need to export the images and the labels\n",
    "# for split in ['train', 'val', 'test']:\n",
    "#     path_to_split = path_to_training_root / split\n",
    "#     try:\n",
    "#         path_to_split.mkdir(exist_ok=False)\n",
    "#     except FileExistsError:\n",
    "#         shutil.rmtree(path_to_split)    \n",
    "#         path_to_split.mkdir()\n",
    "\n",
    "# write_training_data(labels,\n",
    "#                     path_to_training_root,\n",
    "#                     video_data,\n",
    "# )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Example usage\n",
    "# dataset_path = path_to_training_root\n",
    "# train_path = \"train\"  \n",
    "# val_path = \"val\"\n",
    "# test_path = \"test\"\n",
    "\n",
    "# # Get label names from your object organizer\n",
    "# label_id_label_dict = {}\n",
    "# for label_id, label_dict in labels.items():\n",
    "#     label_id_label_dict[label_id] = label_dict['label']\n",
    "\n",
    "# # Write the YAML config\n",
    "# config_path = path_to_training_root / \"yolo_config.yaml\"\n",
    "# write_yolo_config_yaml(\n",
    "#     output_path=config_path,\n",
    "#     dataset_path=dataset_path,\n",
    "#     train_path=train_path,\n",
    "#     val_path=val_path,\n",
    "#     test_path=test_path,\n",
    "#     label_dict=label_id_label_dict\n",
    "# )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## YOLO setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from ultralytics import YOLO\n",
    "# from ultralytics import settings\n",
    "# settings.update({'sync': False,'hub':False, })\n",
    "# runs_output_dir = config_path.parent / 'yolo runs'   \n",
    "# settings.update({'datasets_dir': '','weights_dir':'', 'runs_dir': runs_output_dir.as_posix()})\n",
    "# settings.update()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Load a model\n",
    "# model = YOLO(path_to_model)  # load a pretrained model (recommended for training)\n",
    "# # Train the model\n",
    "# # https://docs.ultralytics.com/usage/cfg/#solutions-settings\n",
    "# results = model.train(data=config_path, \n",
    "#                       save_dir=runs_output_dir.as_posix(),\n",
    "#                       device='cpu',\n",
    "#                       mask_ratio=4,\n",
    "#                       epochs=60,\n",
    "#                       imgsz=640,\n",
    "#                       resume=False,\n",
    "#                       plots=True,\n",
    "#                       batch=.85,\n",
    "#                       cache=False,\n",
    "#                       save=True,\n",
    "#                       save_period=15,\n",
    "#                       project=None,\n",
    "#                       name=None,\n",
    "#                       exist_ok=True,\n",
    "#                       # augmentation\n",
    "#                       hsv_v=.25,\n",
    "#                       degrees=180,\n",
    "#                       scale=.5,\n",
    "#                       shear=2,\n",
    "#                       flipud=.1,\n",
    "#                       fliplr=.1,\n",
    "#                       mosaic=1.0,\n",
    "#                       copy_paste=.5,\n",
    "#                       copy_paste_mode='mixup', \n",
    "#                       erasing=.25,\n",
    "#                       crop_fraction=1.0,\n",
    "#                       )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model = YOLO('/Users/horst/Downloads/octron_project/octron_training/yolo runs/segment/train/weights/last.pt')  #"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# metrics = model.val(device='cpu', plots=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(\"Mean Average Precision for boxes:\", metrics.box.map)\n",
    "# print(\"Mean Average Precision for masks:\", metrics.seg.map)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Run inference on 'bus.jpg' with arguments\n",
    "# model.predict('/Users/horst/Downloads/octron_project/test data/8_behaviour_filtered2024-11-04T14_20_34_20240930_Th19.mp4', \n",
    "#               save=True, \n",
    "#               classes=[0],\n",
    "#               imgsz=1000, \n",
    "#               device='cpu',\n",
    "#               visualize=False,\n",
    "#               conf=0.9\n",
    "#               )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Train/val/test sets as \n",
    "# 1) dir: path/to/imgs, \n",
    "# 2) file: path/to/imgs.txt, or list: [path/to/imgs1, path/to/imgs2, ..]\n",
    "# path: ../datasets/coco8-seg # dataset root dir (absolute or relative; if relative, it's relative to default datasets_dir)\n",
    "# train: images/train # train images (relative to 'path') 4 images\n",
    "# val: images/val # val images (relative to 'path') 4 images\n",
    "# test: # test images (optional)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "sam2",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

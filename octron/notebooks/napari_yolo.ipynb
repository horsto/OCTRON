{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "source": [
    "## Yolo11 tests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os , sys\n",
    "sys.path.append('..')\n",
    "from pathlib import Path\n",
    "cur_path = Path(os.getcwd()).parent\n",
    "sam2_path = cur_path / 'sam2_octron'\n",
    "sys.path.append(cur_path.as_posix())\n",
    "from matplotlib import pyplot as plt\n",
    "import cmasher as cmr\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "sns.set_theme(style='white')\n",
    "%config InlineBackend.figure_format = 'retina'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from octron.yolo_octron.yolo_octron import YOLO_octron\n",
    "from octron.yolo_octron.helpers.yolo_checks import check_yolo_models\n",
    "from octron.yolo_octron.helpers.training import collect_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "base_path = Path('/Users/horst/Documents/python/OCTRON/octron/notebooks').parent\n",
    "models_yaml_path = base_path / 'yolo_octron/yolo_models.yaml'\n",
    "\n",
    "# project_path = Path('/Users/horst/Downloads/octron_project_2')\n",
    "# assert project_path.exists()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Organize training data "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run collect_labels in isolation. This would be triggered if a new project path is chosen\n",
    "#label_dict = collect_labels(project_path)   \n",
    "#label_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# yolo_octron = YOLO_octron(models_yaml_path=models_yaml_path,\n",
    "#                           )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# yolo_octron.project_path = project_path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from ultralytics import settings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# yolo_octron.prepare_labels(\n",
    "#                     prune_empty_labels=True, \n",
    "#                     min_num_frames=10, \n",
    "#                     verbose=False, \n",
    "# )\n",
    "# prepare_polygons = yolo_octron.prepare_polygons()\n",
    "# # Process all yielded values\n",
    "# for no_entry, total_label_dict, label, frame_no, total_frames in prepare_polygons:\n",
    "#     # add progress reporting here \n",
    "#     pass\n",
    "    \n",
    "# print(\"Polygon preparation complete!\")\n",
    "# yolo_octron.prepare_split(\n",
    "#                     training_fraction=0.7,\n",
    "#                     validation_fraction=0.15,\n",
    "#                     verbose=False,\n",
    "# )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create_training_data = yolo_octron.create_training_data()\n",
    "# # Process all yielded values\n",
    "# for no_entry, total_label_dict, label, split, frame_no, total_frames in create_training_data:\n",
    "#     # add progress reporting here \n",
    "#     pass\n",
    "    \n",
    "# yolo_octron.write_yolo_config()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## YOLO training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# _ = yolo_octron.load_model('YOLO11l')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# yolo_octron.launch_tensorboard()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train_results = yolo_octron.train(epochs=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Load a model\n",
    "# import time\n",
    "\n",
    "# path_to_model = Path('/Users/horst/Documents/python/OCTRON/octron/yolo_octron/models/yolo11l-seg.pt')\n",
    "# config_path = Path('/Users/horst/Downloads/octron_project_2/model/training_data/yolo_config.yaml')\n",
    "# path_to_training = Path('/Users/horst/Downloads/octron_project_2/model/training_data')\n",
    "\n",
    "# def on_train_start(trainer):\n",
    "#     print(\"ðŸ¥³  Training is starting!\")\n",
    "\n",
    "# def on_fit_epoch_end(trainer):\n",
    "#     current_epoch = trainer.epoch + 1 \n",
    "#     time_epoch = trainer.epoch_time\n",
    "#     print(f\"Time for epoch: {time_epoch}\")\n",
    "#     remaining_time = time_epoch * (no_epochs - current_epoch)   \n",
    "#     finish_time = time.time() + remaining_time\n",
    "#     finish_time_str = ' '.join(time.ctime(finish_time).split()[:-1])\n",
    "#     print(f\"Estimated time remaining: {remaining_time} seconds\")    \n",
    "#     print(f'Estimated finish time: {finish_time_str}')  \n",
    "    \n",
    "# from ultralytics import YOLO\n",
    "# model = YOLO(path_to_model)  # load a pretrained model (recommended for training)\n",
    "# model.add_callback(\"on_train_start\", on_train_start)\n",
    "# model.add_callback(\"on_fit_epoch_end\", on_fit_epoch_end)\n",
    "# no_epochs = 1\n",
    "\n",
    "# # Train the model\n",
    "# # https://docs.ultralytics.com/usage/cfg/#solutions-settings\n",
    "# results = model.train(data=config_path, \n",
    "#                       save_dir=path_to_training.as_posix(),\n",
    "#                       name='training',\n",
    "#                       mode='segment',\n",
    "#                       device='cpu',\n",
    "#                       mask_ratio=4,\n",
    "#                       epochs=no_epochs,\n",
    "#                       imgsz=640,\n",
    "#                       resume=False,\n",
    "#                       plots=True,\n",
    "#                       batch=.9,\n",
    "#                       cache=False,\n",
    "#                       save=True,\n",
    "#                       save_period=15,\n",
    "#                       project=None,\n",
    "#                       exist_ok=True,\n",
    "#                       # augmentation\n",
    "#                       augment=True,\n",
    "#                       hsv_v=.25,\n",
    "#                       degrees=180,\n",
    "#                       scale=.5,\n",
    "#                       shear=2,\n",
    "#                       flipud=.1,\n",
    "#                       fliplr=.1,\n",
    "#                       mosaic=1.0,\n",
    "#                       copy_paste=.5,\n",
    "#                       copy_paste_mode='mixup', \n",
    "#                       erasing=.25,\n",
    "#                       crop_fraction=1.0,\n",
    "#                       )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "project_path = Path('/Users/horst/Downloads/octron_project_2_trained')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "from natsort import natsorted   \n",
    "import pandas as pd\n",
    "from datetime import datetime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "from ultralytics import YOLO\n",
    "from octron.sam2_octron.helpers.video_loader import probe_video, get_vfile_hash\n",
    "from octron.yolo_octron.helpers.polygons import get_polygons, polygon_to_mask, find_objects_in_mask\n",
    "from octron.yolo_octron.helpers.yolo_zarr import create_prediction_store, create_prediction_zarr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Setup video, zarr store and model "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Napari PyAV reader \n",
    "from napari_pyav._reader import FastVideoReader\n",
    "import napari\n",
    "from collections import defaultdict\n",
    "import cv2\n",
    "import zarr\n",
    "from tqdm.auto import tqdm\n",
    "from octron.sam2_octron.helpers.sam2_zarr import create_image_zarr\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tracker configuration written to /Users/horst/Downloads/octron_project_2_trained/model/training_data/tracker_config.yaml\n",
      "File: /Users/horst/Downloads/octron_project_2/for prediction/8_behaviour_filtered2024-11-04T14_20_34_20240930_Th19.mp4\n",
      "Codec: h264\n",
      "Resolution: 1000 x 1000\n",
      "Frame Rate: 7.0\n",
      "Number of frames: 210\n",
      "Duration: 30.00 seconds\n"
     ]
    }
   ],
   "source": [
    "config_path = Path('/Users/horst/Downloads/octron_project_2_trained/model/training_data/yolo_config.yaml')\n",
    "tracker_yaml_path = config_path.parent / 'tracker_config.yaml'\n",
    "write_byte_tracker_yaml(tracker_yaml_path)   \n",
    "\n",
    "video_for_prediction = '/Users/horst/Downloads/octron_project_2/for prediction/8_behaviour_filtered2024-11-04T14_20_34_20240930_Th19.mp4'\n",
    "video_path = Path(video_for_prediction)\n",
    "video_dict = probe_video(video_path)\n",
    "# Create hash and save it in the metadata\n",
    "video_file_hash = get_vfile_hash(video_path)\n",
    "video_dict['hash'] = video_file_hash # Save it locally as metadata\n",
    "# Layer name \n",
    "layer_name = f'VIDEO [name: {video_path.stem}]'\n",
    "layer_dict = {'name'    : layer_name,\n",
    "              'metadata': video_dict,\n",
    "              }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[PosixPath('/Users/horst/Downloads/octron_project_2_trained/model/segment/training/weights/best.pt'), PosixPath('/Users/horst/Downloads/octron_project_2_trained/model/segment/training/weights/epoch0.pt'), PosixPath('/Users/horst/Downloads/octron_project_2_trained/model/segment/training/weights/epoch20.pt'), PosixPath('/Users/horst/Downloads/octron_project_2_trained/model/segment/training/weights/epoch40.pt'), PosixPath('/Users/horst/Downloads/octron_project_2_trained/model/segment/training/weights/epoch60.pt'), PosixPath('/Users/horst/Downloads/octron_project_2_trained/model/segment/training/weights/last.pt')]\n",
      "Loading /Users/horst/Downloads/octron_project_2_trained/model/segment/training/weights/last.pt\n"
     ]
    }
   ],
   "source": [
    "found_models_project = natsorted(project_path.rglob('*training/weights/*.pt'))\n",
    "print(found_models_project)\n",
    "print(f'Loading {found_models_project[-1]}')\n",
    "\n",
    "# Load the YOLO11 model\n",
    "model = YOLO(found_models_project[-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "video = FastVideoReader(video_for_prediction, read_format='rgb24')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "save_dir = Path(video_for_prediction.replace('.mp4', '_predictions'))\n",
    "os.makedirs(save_dir, exist_ok=True)\n",
    "zarr_store_dir = save_dir / 'predictions.zarr'  # Zarr store directory"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Danger zone"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 217,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'video_hash': '38c4a8c02b23e2518dac1c6400afabcf695e00661d78139073c2b05e7c724296',\n",
       " 'video_name': None,\n",
       " 'video_height': 1000,\n",
       " 'video_width': 1000,\n",
       " 'frame_count': 210,\n",
       " 'created_at': '2025-03-08 09:24:42.591597'}"
      ]
     },
     "execution_count": 217,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create initial zarr store reference\n",
    "prediction_store = create_prediction_store(zarr_store_dir)\n",
    "# Delete previous predictions\n",
    "for file in save_dir.rglob('*'):\n",
    "    os.remove(file)\n",
    "tracking_df = create_tracking_dataframe(video_dict)\n",
    "tracking_df.attrs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 218,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Existing keys in zarr archive: []\n"
     ]
    }
   ],
   "source": [
    "root = zarr.open_group(store=prediction_store, mode='a')\n",
    "print(\"Existing keys in zarr archive:\", list(root.array_keys()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 219,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2d26eda11daf48dc98894aa453a1776e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Processing video:   0%|          | 0/210 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "0: 640x640 1 worm, 2 leds, 249.6ms\n",
      "Speed: 2.2ms preprocess, 249.6ms inference, 2.2ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 worm, 2 leds, 236.3ms\n",
      "Speed: 6.5ms preprocess, 236.3ms inference, 3.4ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 worm, 2 leds, 241.3ms\n",
      "Speed: 2.0ms preprocess, 241.3ms inference, 3.2ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 worm, 2 leds, 238.3ms\n",
      "Speed: 1.6ms preprocess, 238.3ms inference, 3.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 worm, 2 leds, 231.1ms\n",
      "Speed: 1.7ms preprocess, 231.1ms inference, 2.3ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 worm, 2 leds, 252.0ms\n",
      "Speed: 1.9ms preprocess, 252.0ms inference, 2.2ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 worm, 2 leds, 242.5ms\n",
      "Speed: 1.5ms preprocess, 242.5ms inference, 2.4ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 worm, 2 leds, 287.0ms\n",
      "Speed: 1.6ms preprocess, 287.0ms inference, 2.4ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 worm, 2 leds, 239.3ms\n",
      "Speed: 1.8ms preprocess, 239.3ms inference, 2.2ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 worm, 2 leds, 235.4ms\n",
      "Speed: 1.7ms preprocess, 235.4ms inference, 2.4ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 worm, 2 leds, 259.4ms\n",
      "Speed: 1.6ms preprocess, 259.4ms inference, 2.8ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 worm, 2 leds, 266.5ms\n",
      "Speed: 1.8ms preprocess, 266.5ms inference, 2.1ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 worm, 2 leds, 266.9ms\n",
      "Speed: 3.0ms preprocess, 266.9ms inference, 3.2ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 worm, 2 leds, 227.0ms\n",
      "Speed: 1.6ms preprocess, 227.0ms inference, 2.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 worm, 2 leds, 294.7ms\n",
      "Speed: 1.5ms preprocess, 294.7ms inference, 2.1ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 worm, 2 leds, 245.3ms\n",
      "Speed: 2.2ms preprocess, 245.3ms inference, 3.2ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 worm, 2 leds, 342.4ms\n",
      "Speed: 2.4ms preprocess, 342.4ms inference, 3.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 worm, 2 leds, 232.0ms\n",
      "Speed: 2.1ms preprocess, 232.0ms inference, 2.2ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 worm, 2 leds, 243.6ms\n",
      "Speed: 1.9ms preprocess, 243.6ms inference, 2.2ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 worm, 2 leds, 234.5ms\n",
      "Speed: 1.6ms preprocess, 234.5ms inference, 2.2ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 worm, 2 leds, 243.7ms\n",
      "Speed: 1.7ms preprocess, 243.7ms inference, 3.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 worm, 2 leds, 263.4ms\n",
      "Speed: 2.0ms preprocess, 263.4ms inference, 3.1ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 worm, 2 leds, 243.7ms\n",
      "Speed: 1.9ms preprocess, 243.7ms inference, 2.2ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 worm, 2 leds, 247.6ms\n",
      "Speed: 1.9ms preprocess, 247.6ms inference, 3.1ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 worm, 2 leds, 242.0ms\n",
      "Speed: 1.7ms preprocess, 242.0ms inference, 2.8ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 worm, 2 leds, 258.6ms\n",
      "Speed: 1.6ms preprocess, 258.6ms inference, 2.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 worm, 2 leds, 242.8ms\n",
      "Speed: 2.2ms preprocess, 242.8ms inference, 2.4ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 worm, 2 leds, 245.7ms\n",
      "Speed: 1.8ms preprocess, 245.7ms inference, 2.1ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 worm, 2 leds, 230.5ms\n",
      "Speed: 1.7ms preprocess, 230.5ms inference, 2.3ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 worm, 2 leds, 278.4ms\n",
      "Speed: 1.7ms preprocess, 278.4ms inference, 3.1ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 worm, 2 leds, 266.1ms\n",
      "Speed: 1.6ms preprocess, 266.1ms inference, 3.7ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 worm, 2 leds, 266.5ms\n",
      "Speed: 1.6ms preprocess, 266.5ms inference, 2.3ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 worm, 2 leds, 292.7ms\n",
      "Speed: 1.6ms preprocess, 292.7ms inference, 3.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 worm, 2 leds, 300.3ms\n",
      "Speed: 1.7ms preprocess, 300.3ms inference, 3.3ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 worm, 2 leds, 274.8ms\n",
      "Speed: 1.8ms preprocess, 274.8ms inference, 2.2ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 worm, 2 leds, 242.1ms\n",
      "Speed: 1.6ms preprocess, 242.1ms inference, 2.4ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 worm, 2 leds, 242.0ms\n",
      "Speed: 2.1ms preprocess, 242.0ms inference, 2.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 worm, 2 leds, 225.1ms\n",
      "Speed: 1.9ms preprocess, 225.1ms inference, 2.4ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 worm, 2 leds, 234.6ms\n",
      "Speed: 1.9ms preprocess, 234.6ms inference, 2.1ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 worm, 2 leds, 226.6ms\n",
      "Speed: 2.2ms preprocess, 226.6ms inference, 2.1ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 worm, 2 leds, 226.7ms\n",
      "Speed: 1.8ms preprocess, 226.7ms inference, 2.1ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 worm, 2 leds, 236.1ms\n",
      "Speed: 1.7ms preprocess, 236.1ms inference, 2.3ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 worm, 2 leds, 234.5ms\n",
      "Speed: 1.5ms preprocess, 234.5ms inference, 2.1ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 worm, 2 leds, 237.9ms\n",
      "Speed: 1.9ms preprocess, 237.9ms inference, 2.4ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 worm, 2 leds, 234.5ms\n",
      "Speed: 1.6ms preprocess, 234.5ms inference, 2.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 worm, 2 leds, 256.3ms\n",
      "Speed: 1.7ms preprocess, 256.3ms inference, 2.3ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 worm, 2 leds, 240.9ms\n",
      "Speed: 2.6ms preprocess, 240.9ms inference, 3.2ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 worm, 2 leds, 238.1ms\n",
      "Speed: 2.1ms preprocess, 238.1ms inference, 2.1ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 worm, 2 leds, 239.8ms\n",
      "Speed: 1.6ms preprocess, 239.8ms inference, 2.1ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 worm, 2 leds, 255.3ms\n",
      "Speed: 1.6ms preprocess, 255.3ms inference, 4.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 worm, 2 leds, 269.2ms\n",
      "Speed: 1.5ms preprocess, 269.2ms inference, 3.3ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 worm, 2 leds, 280.5ms\n",
      "Speed: 2.3ms preprocess, 280.5ms inference, 3.1ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 worm, 2 leds, 236.0ms\n",
      "Speed: 1.7ms preprocess, 236.0ms inference, 2.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 worm, 2 leds, 230.1ms\n",
      "Speed: 1.7ms preprocess, 230.1ms inference, 2.4ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 worm, 2 leds, 228.7ms\n",
      "Speed: 1.6ms preprocess, 228.7ms inference, 2.1ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 worm, 2 leds, 235.1ms\n",
      "Speed: 1.7ms preprocess, 235.1ms inference, 2.4ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 worm, 2 leds, 241.6ms\n",
      "Speed: 1.6ms preprocess, 241.6ms inference, 2.3ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 worm, 2 leds, 239.6ms\n",
      "Speed: 1.7ms preprocess, 239.6ms inference, 2.1ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 worm, 2 leds, 240.9ms\n",
      "Speed: 1.9ms preprocess, 240.9ms inference, 3.4ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 worm, 2 leds, 233.4ms\n",
      "Speed: 2.2ms preprocess, 233.4ms inference, 2.1ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 worm, 2 leds, 239.8ms\n",
      "Speed: 1.5ms preprocess, 239.8ms inference, 2.2ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 worm, 2 leds, 241.1ms\n",
      "Speed: 2.0ms preprocess, 241.1ms inference, 2.9ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 worm, 2 leds, 253.7ms\n",
      "Speed: 1.8ms preprocess, 253.7ms inference, 4.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 worm, 2 leds, 298.0ms\n",
      "Speed: 1.7ms preprocess, 298.0ms inference, 3.2ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 worm, 2 leds, 241.5ms\n",
      "Speed: 1.5ms preprocess, 241.5ms inference, 2.3ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 worm, 2 leds, 251.1ms\n",
      "Speed: 1.7ms preprocess, 251.1ms inference, 2.8ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 worm, 2 leds, 233.2ms\n",
      "Speed: 1.7ms preprocess, 233.2ms inference, 2.1ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 worm, 2 leds, 265.3ms\n",
      "Speed: 1.9ms preprocess, 265.3ms inference, 2.2ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 worm, 2 leds, 269.9ms\n",
      "Speed: 1.5ms preprocess, 269.9ms inference, 3.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 worm, 2 leds, 255.3ms\n",
      "Speed: 1.6ms preprocess, 255.3ms inference, 2.3ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 worm, 2 leds, 263.3ms\n",
      "Speed: 2.1ms preprocess, 263.3ms inference, 2.2ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 worm, 2 leds, 229.1ms\n",
      "Speed: 1.9ms preprocess, 229.1ms inference, 2.2ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 worm, 2 leds, 240.1ms\n",
      "Speed: 1.6ms preprocess, 240.1ms inference, 3.3ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 worm, 2 leds, 239.9ms\n",
      "Speed: 1.8ms preprocess, 239.9ms inference, 2.3ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 worm, 2 leds, 229.0ms\n",
      "Speed: 1.5ms preprocess, 229.0ms inference, 2.2ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 worm, 2 leds, 236.2ms\n",
      "Speed: 1.7ms preprocess, 236.2ms inference, 2.1ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 worm, 2 leds, 248.2ms\n",
      "Speed: 1.6ms preprocess, 248.2ms inference, 3.1ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 worm, 2 leds, 243.7ms\n",
      "Speed: 1.9ms preprocess, 243.7ms inference, 2.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 worm, 2 leds, 257.5ms\n",
      "Speed: 1.5ms preprocess, 257.5ms inference, 2.9ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 worm, 2 leds, 270.5ms\n",
      "Speed: 1.7ms preprocess, 270.5ms inference, 2.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 worm, 2 leds, 240.8ms\n",
      "Speed: 1.6ms preprocess, 240.8ms inference, 2.3ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 worm, 2 leds, 235.2ms\n",
      "Speed: 1.6ms preprocess, 235.2ms inference, 2.1ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 worm, 2 leds, 228.3ms\n",
      "Speed: 1.8ms preprocess, 228.3ms inference, 2.1ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 worm, 2 leds, 224.0ms\n",
      "Speed: 1.6ms preprocess, 224.0ms inference, 2.7ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 worm, 2 leds, 254.5ms\n",
      "Speed: 1.6ms preprocess, 254.5ms inference, 2.1ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 worm, 2 leds, 231.3ms\n",
      "Speed: 1.7ms preprocess, 231.3ms inference, 2.2ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 worm, 2 leds, 231.6ms\n",
      "Speed: 1.6ms preprocess, 231.6ms inference, 2.3ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 worm, 2 leds, 226.4ms\n",
      "Speed: 1.6ms preprocess, 226.4ms inference, 2.1ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 worm, 2 leds, 244.4ms\n",
      "Speed: 1.5ms preprocess, 244.4ms inference, 2.3ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 worm, 2 leds, 228.3ms\n",
      "Speed: 1.5ms preprocess, 228.3ms inference, 2.1ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 worm, 2 leds, 232.4ms\n",
      "Speed: 1.6ms preprocess, 232.4ms inference, 2.1ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 worm, 2 leds, 235.2ms\n",
      "Speed: 1.5ms preprocess, 235.2ms inference, 2.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 worm, 2 leds, 244.5ms\n",
      "Speed: 1.5ms preprocess, 244.5ms inference, 3.4ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 worm, 2 leds, 225.6ms\n",
      "Speed: 1.6ms preprocess, 225.6ms inference, 2.1ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 worm, 2 leds, 233.3ms\n",
      "Speed: 1.6ms preprocess, 233.3ms inference, 2.1ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 worm, 1 led, 225.1ms\n",
      "Speed: 1.5ms preprocess, 225.1ms inference, 2.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 worm, 1 led, 235.0ms\n",
      "Speed: 1.5ms preprocess, 235.0ms inference, 2.2ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 worm, 1 led, 232.8ms\n",
      "Speed: 2.1ms preprocess, 232.8ms inference, 1.9ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 worm, 1 led, 228.2ms\n",
      "Speed: 2.0ms preprocess, 228.2ms inference, 1.8ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 worm, 1 led, 241.2ms\n",
      "Speed: 1.7ms preprocess, 241.2ms inference, 3.1ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 worm, 1 led, 268.8ms\n",
      "Speed: 1.8ms preprocess, 268.8ms inference, 3.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 worm, 1 led, 228.8ms\n",
      "Speed: 1.7ms preprocess, 228.8ms inference, 1.8ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 worm, 1 led, 247.9ms\n",
      "Speed: 1.6ms preprocess, 247.9ms inference, 1.9ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 worm, 1 led, 235.6ms\n",
      "Speed: 1.5ms preprocess, 235.6ms inference, 2.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 worm, 1 led, 256.4ms\n",
      "Speed: 1.6ms preprocess, 256.4ms inference, 3.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 worm, 1 led, 263.5ms\n",
      "Speed: 2.4ms preprocess, 263.5ms inference, 2.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 worm, 1 led, 270.2ms\n",
      "Speed: 1.7ms preprocess, 270.2ms inference, 2.7ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 worm, 1 led, 278.6ms\n",
      "Speed: 1.7ms preprocess, 278.6ms inference, 3.2ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 worm, 1 led, 266.1ms\n",
      "Speed: 1.6ms preprocess, 266.1ms inference, 2.9ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 worm, 1 led, 243.9ms\n",
      "Speed: 1.6ms preprocess, 243.9ms inference, 1.7ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 worm, 1 led, 246.1ms\n",
      "Speed: 1.7ms preprocess, 246.1ms inference, 1.9ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 worm, 1 led, 231.3ms\n",
      "Speed: 2.1ms preprocess, 231.3ms inference, 1.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 worm, 2 leds, 254.1ms\n",
      "Speed: 2.1ms preprocess, 254.1ms inference, 3.8ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 worm, 1 led, 272.6ms\n",
      "Speed: 1.6ms preprocess, 272.6ms inference, 2.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 worm, 1 led, 283.2ms\n",
      "Speed: 2.1ms preprocess, 283.2ms inference, 2.9ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 worm, 2 leds, 230.4ms\n",
      "Speed: 1.6ms preprocess, 230.4ms inference, 3.2ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 worm, 2 leds, 249.9ms\n",
      "Speed: 1.6ms preprocess, 249.9ms inference, 2.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 worm, 2 leds, 242.4ms\n",
      "Speed: 1.5ms preprocess, 242.4ms inference, 2.2ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 worm, 2 leds, 233.2ms\n",
      "Speed: 2.2ms preprocess, 233.2ms inference, 2.1ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 worm, 2 leds, 274.1ms\n",
      "Speed: 1.7ms preprocess, 274.1ms inference, 4.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 worm, 2 leds, 274.0ms\n",
      "Speed: 2.1ms preprocess, 274.0ms inference, 2.3ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 worm, 2 leds, 234.4ms\n",
      "Speed: 1.7ms preprocess, 234.4ms inference, 2.2ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 worm, 2 leds, 236.4ms\n",
      "Speed: 1.5ms preprocess, 236.4ms inference, 2.4ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 worm, 2 leds, 302.4ms\n",
      "Speed: 1.7ms preprocess, 302.4ms inference, 3.1ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 worm, 2 leds, 226.5ms\n",
      "Speed: 1.8ms preprocess, 226.5ms inference, 2.4ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 worm, 2 leds, 241.8ms\n",
      "Speed: 1.5ms preprocess, 241.8ms inference, 2.7ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 worm, 2 leds, 245.1ms\n",
      "Speed: 1.5ms preprocess, 245.1ms inference, 2.2ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 worm, 2 leds, 246.5ms\n",
      "Speed: 1.6ms preprocess, 246.5ms inference, 2.8ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 worm, 2 leds, 253.0ms\n",
      "Speed: 1.7ms preprocess, 253.0ms inference, 2.3ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 worm, 2 leds, 228.9ms\n",
      "Speed: 1.6ms preprocess, 228.9ms inference, 2.1ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 worm, 2 leds, 260.7ms\n",
      "Speed: 1.6ms preprocess, 260.7ms inference, 3.9ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 worm, 2 leds, 272.7ms\n",
      "Speed: 1.9ms preprocess, 272.7ms inference, 3.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 worm, 2 leds, 250.1ms\n",
      "Speed: 1.6ms preprocess, 250.1ms inference, 3.1ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 worm, 2 leds, 240.4ms\n",
      "Speed: 2.2ms preprocess, 240.4ms inference, 2.2ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 worm, 2 leds, 258.0ms\n",
      "Speed: 1.7ms preprocess, 258.0ms inference, 3.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 worm, 2 leds, 262.7ms\n",
      "Speed: 1.6ms preprocess, 262.7ms inference, 2.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 worm, 2 leds, 268.3ms\n",
      "Speed: 2.6ms preprocess, 268.3ms inference, 3.1ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 worm, 2 leds, 244.0ms\n",
      "Speed: 1.7ms preprocess, 244.0ms inference, 2.2ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 worm, 2 leds, 230.7ms\n",
      "Speed: 1.9ms preprocess, 230.7ms inference, 2.9ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 worm, 2 leds, 241.7ms\n",
      "Speed: 1.6ms preprocess, 241.7ms inference, 2.2ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 worm, 2 leds, 238.3ms\n",
      "Speed: 1.8ms preprocess, 238.3ms inference, 2.1ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 worm, 2 leds, 261.3ms\n",
      "Speed: 1.8ms preprocess, 261.3ms inference, 2.4ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 worm, 2 leds, 228.6ms\n",
      "Speed: 1.6ms preprocess, 228.6ms inference, 2.1ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 worm, 2 leds, 225.7ms\n",
      "Speed: 1.7ms preprocess, 225.7ms inference, 2.2ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 worm, 2 leds, 243.7ms\n",
      "Speed: 1.7ms preprocess, 243.7ms inference, 2.2ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 worm, 2 leds, 240.8ms\n",
      "Speed: 2.4ms preprocess, 240.8ms inference, 2.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 worm, 2 leds, 271.5ms\n",
      "Speed: 1.7ms preprocess, 271.5ms inference, 4.3ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 worm, 2 leds, 243.7ms\n",
      "Speed: 1.5ms preprocess, 243.7ms inference, 2.1ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 worm, 2 leds, 245.2ms\n",
      "Speed: 1.5ms preprocess, 245.2ms inference, 2.1ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 worm, 2 leds, 229.1ms\n",
      "Speed: 1.6ms preprocess, 229.1ms inference, 2.1ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 worm, 2 leds, 239.1ms\n",
      "Speed: 1.6ms preprocess, 239.1ms inference, 4.3ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 worm, 2 leds, 226.5ms\n",
      "Speed: 1.6ms preprocess, 226.5ms inference, 2.2ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 worm, 2 leds, 235.0ms\n",
      "Speed: 1.9ms preprocess, 235.0ms inference, 2.2ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 worm, 2 leds, 222.9ms\n",
      "Speed: 1.6ms preprocess, 222.9ms inference, 2.7ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 worm, 2 leds, 241.4ms\n",
      "Speed: 2.0ms preprocess, 241.4ms inference, 2.2ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 worm, 2 leds, 237.9ms\n",
      "Speed: 2.0ms preprocess, 237.9ms inference, 2.4ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 worm, 2 leds, 239.4ms\n",
      "Speed: 2.2ms preprocess, 239.4ms inference, 2.9ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 worm, 2 leds, 231.1ms\n",
      "Speed: 1.8ms preprocess, 231.1ms inference, 2.1ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 worm, 2 leds, 253.8ms\n",
      "Speed: 1.6ms preprocess, 253.8ms inference, 2.4ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 worm, 2 leds, 232.9ms\n",
      "Speed: 1.7ms preprocess, 232.9ms inference, 2.4ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 worm, 2 leds, 242.8ms\n",
      "Speed: 1.6ms preprocess, 242.8ms inference, 2.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 worm, 2 leds, 232.0ms\n",
      "Speed: 1.5ms preprocess, 232.0ms inference, 2.2ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 worm, 2 leds, 248.4ms\n",
      "Speed: 1.6ms preprocess, 248.4ms inference, 2.3ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 worm, 2 leds, 226.6ms\n",
      "Speed: 1.5ms preprocess, 226.6ms inference, 2.2ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 worm, 2 leds, 241.7ms\n",
      "Speed: 1.5ms preprocess, 241.7ms inference, 2.1ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 worm, 2 leds, 232.3ms\n",
      "Speed: 1.6ms preprocess, 232.3ms inference, 2.3ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 worm, 2 leds, 241.8ms\n",
      "Speed: 1.5ms preprocess, 241.8ms inference, 2.1ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 worm, 2 leds, 227.7ms\n",
      "Speed: 1.6ms preprocess, 227.7ms inference, 2.4ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 worm, 2 leds, 229.7ms\n",
      "Speed: 1.6ms preprocess, 229.7ms inference, 2.8ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 worm, 2 leds, 237.4ms\n",
      "Speed: 1.6ms preprocess, 237.4ms inference, 2.3ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 worm, 2 leds, 223.9ms\n",
      "Speed: 1.5ms preprocess, 223.9ms inference, 2.3ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 worm, 2 leds, 237.6ms\n",
      "Speed: 1.6ms preprocess, 237.6ms inference, 2.4ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 worm, 2 leds, 267.8ms\n",
      "Speed: 1.7ms preprocess, 267.8ms inference, 2.9ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 worm, 2 leds, 226.1ms\n",
      "Speed: 1.5ms preprocess, 226.1ms inference, 2.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 worm, 2 leds, 237.5ms\n",
      "Speed: 1.8ms preprocess, 237.5ms inference, 2.1ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 worm, 2 leds, 233.7ms\n",
      "Speed: 1.6ms preprocess, 233.7ms inference, 2.3ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 worm, 2 leds, 234.8ms\n",
      "Speed: 1.9ms preprocess, 234.8ms inference, 2.2ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 worm, 2 leds, 241.6ms\n",
      "Speed: 1.6ms preprocess, 241.6ms inference, 6.4ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 worm, 2 leds, 235.0ms\n",
      "Speed: 1.7ms preprocess, 235.0ms inference, 2.3ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 worm, 2 leds, 227.5ms\n",
      "Speed: 1.7ms preprocess, 227.5ms inference, 2.4ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 worm, 2 leds, 244.1ms\n",
      "Speed: 1.6ms preprocess, 244.1ms inference, 2.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 worm, 2 leds, 229.5ms\n",
      "Speed: 1.5ms preprocess, 229.5ms inference, 2.1ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 worm, 2 leds, 236.2ms\n",
      "Speed: 1.5ms preprocess, 236.2ms inference, 2.1ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 worm, 2 leds, 239.9ms\n",
      "Speed: 1.7ms preprocess, 239.9ms inference, 2.2ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 worm, 2 leds, 222.5ms\n",
      "Speed: 1.8ms preprocess, 222.5ms inference, 2.7ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 worm, 2 leds, 243.0ms\n",
      "Speed: 1.6ms preprocess, 243.0ms inference, 2.3ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 worm, 2 leds, 227.6ms\n",
      "Speed: 1.8ms preprocess, 227.6ms inference, 2.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 worm, 2 leds, 235.8ms\n",
      "Speed: 1.8ms preprocess, 235.8ms inference, 2.1ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 worm, 2 leds, 228.3ms\n",
      "Speed: 1.5ms preprocess, 228.3ms inference, 2.1ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 worm, 2 leds, 235.3ms\n",
      "Speed: 1.6ms preprocess, 235.3ms inference, 2.2ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 worm, 2 leds, 230.5ms\n",
      "Speed: 1.6ms preprocess, 230.5ms inference, 2.1ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 worm, 2 leds, 233.8ms\n",
      "Speed: 1.6ms preprocess, 233.8ms inference, 2.3ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 worm, 2 leds, 268.3ms\n",
      "Speed: 1.6ms preprocess, 268.3ms inference, 2.2ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 worm, 2 leds, 241.6ms\n",
      "Speed: 1.5ms preprocess, 241.6ms inference, 2.2ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 worm, 2 leds, 243.5ms\n",
      "Speed: 1.5ms preprocess, 243.5ms inference, 2.2ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 worm, 2 leds, 240.6ms\n",
      "Speed: 1.7ms preprocess, 240.6ms inference, 2.1ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 worm, 2 leds, 227.8ms\n",
      "Speed: 1.6ms preprocess, 227.8ms inference, 2.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 worm, 2 leds, 229.2ms\n",
      "Speed: 1.8ms preprocess, 229.2ms inference, 2.1ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 worm, 2 leds, 226.9ms\n",
      "Speed: 1.5ms preprocess, 226.9ms inference, 2.1ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 worm, 2 leds, 224.4ms\n",
      "Speed: 1.5ms preprocess, 224.4ms inference, 2.4ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 worm, 2 leds, 239.3ms\n",
      "Speed: 1.5ms preprocess, 239.3ms inference, 2.1ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 worm, 2 leds, 229.3ms\n",
      "Speed: 1.9ms preprocess, 229.3ms inference, 2.3ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 worm, 2 leds, 233.3ms\n",
      "Speed: 1.7ms preprocess, 233.3ms inference, 2.1ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 worm, 2 leds, 230.6ms\n",
      "Speed: 1.7ms preprocess, 230.6ms inference, 2.2ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 worm, 2 leds, 234.9ms\n",
      "Speed: 1.5ms preprocess, 234.9ms inference, 2.1ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 worm, 2 leds, 235.1ms\n",
      "Speed: 1.6ms preprocess, 235.1ms inference, 2.2ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 worm, 2 leds, 239.1ms\n",
      "Speed: 1.5ms preprocess, 239.1ms inference, 2.2ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 worm, 2 leds, 239.6ms\n",
      "Speed: 1.4ms preprocess, 239.6ms inference, 2.3ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 worm, 2 leds, 232.1ms\n",
      "Speed: 1.7ms preprocess, 232.1ms inference, 2.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 worm, 1 led, 229.2ms\n",
      "Speed: 2.0ms preprocess, 229.2ms inference, 2.2ms postprocess per image at shape (1, 3, 640, 640)\n"
     ]
    }
   ],
   "source": [
    "zarr_root = zarr.open_group(store=prediction_store, mode='a')\n",
    "poly_smooth_sigma = 1.5\n",
    "tracking_df_dict = {}\n",
    "for frame_no, frame in enumerate(tqdm(video, \n",
    "                                      total=video_dict['num_frames'], \n",
    "                                      desc='Processing video')\n",
    "                                 ):  \n",
    "    # Run YOLO11 tracking on the frame, persisting tracks between frames\n",
    "    results = model.track(source=frame, \n",
    "                          persist=True,\n",
    "                          task='segment',   \n",
    "                          tracker=tracker_yaml_path.as_posix(),\n",
    "                          project=save_dir.parent.as_posix(),\n",
    "                          name=save_dir.name,\n",
    "                          show=False,\n",
    "                          save=False,   \n",
    "                          conf=.75,    \n",
    "                          iou=.8,\n",
    "                          device='cpu', \n",
    "                          half=False,\n",
    "                          retina_masks=True,\n",
    "                          show_boxes=False,\n",
    "                          save_txt=False,\n",
    "                          save_conf=False,   \n",
    "                          )\n",
    "    \n",
    "    # Get the boxes and track IDs\n",
    "    boxes = results[0].boxes.xywh.cpu()\n",
    "    confidences = results[0].boxes.conf.cpu().numpy()\n",
    "    label_names = tuple([results[0].names[int(r)] for r in results[0].boxes.cls.cpu().numpy()])\n",
    "    \n",
    "    masks_polys = results[0].masks.xy  \n",
    "    track_ids = results[0].boxes.id.int().cpu().tolist()\n",
    "    \n",
    "    # Extract tracks \n",
    "    for label, box, mask_poly, track_id, conf in zip(label_names, \n",
    "                                                boxes, \n",
    "                                                masks_polys, \n",
    "                                                track_ids, \n",
    "                                                confidences\n",
    "                                                ):\n",
    "        # Initialize mask zarr array if needed\n",
    "        if f'{track_id}_masks' not in list(zarr_root.array_keys()):\n",
    "            video_shape = (video_dict['num_frames'], video_dict['height'], video_dict['width'])   \n",
    "            mask_store = create_prediction_zarr(prediction_store, \n",
    "                            f'{track_id}_masks',\n",
    "                            shape=video_shape,\n",
    "                            chunk_size=50,     \n",
    "                            fill_value=-1,\n",
    "                            dtype='int8',                           \n",
    "                            video_hash=video_file_hash\n",
    "                            )\n",
    "            mask_store.attrs['label'] = label\n",
    "            mask_store.attrs['classes'] = results[0].names\n",
    "        else:\n",
    "            mask_store = zarr_root[f'{track_id}_masks']\n",
    "        # Initialize dataframe if needed\n",
    "        if track_id not in tracking_df_dict:\n",
    "            tracking_df = create_tracking_dataframe(video_dict)\n",
    "            tracking_df.attrs['label'] = label\n",
    "            tracking_df.attrs['track_id'] = track_id\n",
    "            # Add to the dictionary\n",
    "            tracking_df_dict[track_id] = tracking_df\n",
    "        else:\n",
    "            tracking_df = tracking_df_dict[track_id]\n",
    "            assert tracking_df.attrs['track_id'] == track_id, \"ID mismatch\" \n",
    "            assert tracking_df.attrs['label'] == label, \"Label mismatch\"    \n",
    "        \n",
    "        # Masks\n",
    "        dummy_mask = np.zeros((video_dict['height'], video_dict['width']))    \n",
    "        mask = polygon_to_mask(dummy_mask.astype('int8'), \n",
    "                               mask_poly, \n",
    "                               smooth_sigma=poly_smooth_sigma\n",
    "                               )\n",
    "        mask_store[frame_no,:,:] = mask\n",
    "        \n",
    "        # Get region properties and save them to the dataframe\n",
    "        labels, regions_props = find_objects_in_mask(mask, min_area=0)\n",
    "        assert len(regions_props) == 1\n",
    "        region_prop = regions_props[0]\n",
    "        # ... extract all the properties we want to track\n",
    "        centroid = region_prop.centroid\n",
    "        area = region_prop.area\n",
    "        eccentricity = region_prop.eccentricity\n",
    "        orientation = region_prop.orientation\n",
    "        solidity = region_prop.solidity \n",
    "        \n",
    "        # Store data in DataFrame with flat column names\n",
    "        tracking_df.loc[(frame_no, track_id), 'pos_x'] = centroid[1]  # x coordinate\n",
    "        tracking_df.loc[(frame_no, track_id), 'pos_y'] = centroid[0]  # y coordinate\n",
    "        tracking_df.loc[(frame_no, track_id), 'area'] = area\n",
    "        tracking_df.loc[(frame_no, track_id), 'eccentricity'] = eccentricity\n",
    "        tracking_df.loc[(frame_no, track_id), 'orientation'] = orientation\n",
    "        tracking_df.loc[(frame_no, track_id), 'confidence'] = conf\n",
    "        tracking_df.loc[(frame_no, track_id), 'solidity'] = solidity\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 221,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved tracking data for 'worm' (track ID: 1) to worm_track_1.csv\n",
      "Saved tracking data for 'led' (track ID: 2) to led_track_2.csv\n",
      "Saved tracking data for 'led' (track ID: 3) to led_track_3.csv\n"
     ]
    }
   ],
   "source": [
    "# Save each tracking DataFrame with a label column added\n",
    "for track_id, tr_df in tracking_df_dict.items():\n",
    "    label = tr_df.attrs[\"label\"]\n",
    "    df_to_save = tr_df.copy()\n",
    "    # Add the label column (will be filled with the same value for all rows)\n",
    "    df_to_save.insert(0, 'label', label)\n",
    "    # Save to CSV \n",
    "    filename = f'{label}_track_{track_id}.csv'\n",
    "    csv_path = save_dir / filename\n",
    "    df_to_save.to_csv(csv_path)\n",
    "    print(f\"Saved tracking data for '{label}' (track ID: {track_id}) to {filename}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Read folder of tracking results back in"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 222,
   "metadata": {},
   "outputs": [],
   "source": [
    "import zarr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 223,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 3 tracking CSV files\n",
      "Found zarr file: /Users/horst/Downloads/octron_project_2/for prediction/8_behaviour_filtered2024-11-04T14_20_34_20240930_Th19_predictions/predictions.zarr\n"
     ]
    }
   ],
   "source": [
    "csvs = list(save_dir.rglob('*.csv'))\n",
    "print(f\"Found {len(csvs)} tracking CSV files\")\n",
    "zarr_files = list(save_dir.rglob('*.zarr'))\n",
    "assert len(zarr_files) == 1, \"Expected exactly one zarr file\"\n",
    "zarr_file = zarr_files[0]\n",
    "print(f\"Found zarr file: {zarr_file}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 224,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Existing keys in zarr archive: ['3_masks', '1_masks', '2_masks']\n"
     ]
    }
   ],
   "source": [
    "# Load zarr\n",
    "store = zarr.storage.LocalStore(zarr_file, read_only=False)\n",
    "root = zarr.open_group(store=store, mode='a')\n",
    "print(\"Existing keys in zarr archive:\", list(root.array_keys()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "1\n",
      "1\n"
     ]
    }
   ],
   "source": [
    "# fig, ax = plt.subplots(1, 1, figsize=(6, 6))\n",
    "# dummy_mask=np.zeros((video_dict['height'], video_dict['width']))\n",
    "# ax.imshow(dummy_mask, cmap='gray')  \n",
    "# plot_every_n_mask = 11\n",
    "def find_class_by_name(classes, class_name):\n",
    "    return (next((k for k, v in classes.items() if v == class_name), None))\n",
    "\n",
    "# Color handling\n",
    "from napari.utils import DirectLabelColormap\n",
    "from octron.sam2_octron.helpers.sam2_colors import create_label_colors, sample_maximally_different\n",
    "all_labels_submaps = create_label_colors(n_labels=10,\n",
    "                                         n_colors_submap=50\n",
    "                                         )\n",
    "indices_max_diff_labels = sample_maximally_different(list(range(10)))\n",
    "indices_max_diff_subcolors = sample_maximally_different(list(range(50)))\n",
    "\n",
    "\n",
    "track_df_dict = {}\n",
    "color_dict = {}\n",
    "label_trackid_dict = {}\n",
    "label_counter_dict = {} # This is to find the right color in all_labels_submaps\n",
    "\n",
    "# Load the tracking data\n",
    "for csv in save_dir.glob('*.csv'):\n",
    "    track_df = pd.read_csv(csv)\n",
    "    assert len(track_df.label.unique()) == 1, \"Multiple labels found in tracking data\"  \n",
    "    assert len(track_df.track_id.unique()) == 1, \"Multiple track_ids found in tracking data\"  \n",
    "    label = track_df.iloc[0].label\n",
    "    track_id = track_df.iloc[0].track_id\n",
    "    label_trackid_dict[label] = track_id\n",
    "    \n",
    "    # Check zarr\n",
    "    assert f'{track_id}_masks' in list(root.array_keys()), \"Mask not found in zarr archive\" \n",
    "    mask_zarr = root[f'{track_id}_masks']\n",
    "    classes = mask_zarr.attrs.get('classes', None) # These are the original classes from the model\n",
    "    original_class_id = find_class_by_name(classes,label)\n",
    "    # Check if an index was already given for the current label\n",
    "    # This is to extract the right color from the colormap\n",
    "    if label not in label_counter_dict:\n",
    "        label_counter_dict[label] = {'track_counter' : 0}\n",
    "    else:\n",
    "        label_counter_dict[label]['track_counter'] += 1\n",
    "    # Find color \n",
    "    obj_color =  all_labels_submaps[indices_max_diff_labels[int(original_class_id)]][indices_max_diff_subcolors[label_counter_dict[label]['track_counter']]]\n",
    "    \n",
    "    mask_colors = DirectLabelColormap(color_dict={None: [0.,0.,0.,0.], 1: obj_color}, \n",
    "                                              use_selection=True, \n",
    "                                              selection=1,\n",
    "                                              )\n",
    "        \n",
    "        \n",
    "    color_dict[int(track_id)] = mask_colors\n",
    "    track_df_dict[int(track_id)] = track_df\n",
    "    assert f'{track_id}_masks' in list(root.array_keys()), \"Mask not found in zarr archive\" \n",
    "    mask_zarr = root[f'{track_id}_masks']\n",
    "    \n",
    "#     #Plot the track on the dummy mask\n",
    "    \n",
    "#     ax.scatter(track_df['pos_x'], \n",
    "#                track_df['pos_y'], \n",
    "#                s=track_df['area']/400, \n",
    "#                label=label, \n",
    "#                alpha=.6\n",
    "#                )\n",
    "#     track_outline = np.zeros_like(dummy_mask)\n",
    "#     for frame_no in range(0, video_dict['num_frames'], plot_every_n_mask):\n",
    "#         mask = mask_zarr[frame_no,:,:]\n",
    "#         if mask[0,0] == -1:\n",
    "#             continue\n",
    "        \n",
    "#         polygon_points = get_polygons(mask)\n",
    "#          # Check if polygon_points is valid\n",
    "#         if polygon_points is None or len(polygon_points) == 0:\n",
    "#             continue\n",
    "            \n",
    "#         # Ensure polygon_points is properly formatted for cv2.polylines\n",
    "#         if isinstance(polygon_points, np.ndarray):\n",
    "#             # Convert to list of numpy arrays if it's a single array\n",
    "#             if len(polygon_points.shape) == 2:  # Single polygon\n",
    "#                 polygon_points = [polygon_points]\n",
    "            \n",
    "#             # Draw each polygon\n",
    "#             for poly in polygon_points:\n",
    "#                 # Ensure the points are properly shaped and have integer coordinates\n",
    "#                 if len(poly) > 2:  # Need at least 3 points to form a polygon\n",
    "#                     poly_reshaped = poly.reshape((-1, 1, 2)).astype(np.int32)\n",
    "#                     try:\n",
    "#                         track_outline = cv2.polylines(\n",
    "#                             img=track_outline.copy(), \n",
    "#                             pts=[poly_reshaped],\n",
    "#                             isClosed=True, \n",
    "#                             color=(255, 255, 255),  \n",
    "#                             thickness=2,\n",
    "#                         )\n",
    "#                     except Exception as e:\n",
    "#                         print(f\"Error with polygon: {e}\")\n",
    "#                         print(f\"Polygon shape: {poly.shape}, dtype: {poly.dtype}\")\n",
    "    \n",
    "#     # Add the track outline to the main plot\n",
    "#     if np.any(track_outline > 0):\n",
    "#         ax.imshow(track_outline, cmap='gray', alpha=0.3)\n",
    "    \n",
    "# ax.legend()\n",
    "# ax.set_xticks([]);\n",
    "# ax.set_yticks([]);\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Add predictions back to napari "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 242,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.ndimage import gaussian_filter1d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Image layer 'VIDEO [name: 8_behaviour_filtered2024-11-04T14_20_34_20240930_Th19]' at 0x35bb6d410>"
      ]
     },
     "execution_count": 243,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "viewer = napari.Viewer()    \n",
    "\n",
    "add_layer = getattr(viewer, \"add_image\")\n",
    "add_layer(video, **layer_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 260,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Frames are not continuous ... interpolating\n"
     ]
    }
   ],
   "source": [
    "sigmal_tracking_pos = 1\n",
    "min_frame = 0\n",
    "max_frame = video_dict['num_frames'] \n",
    "\n",
    "# Loop over each track and add it to the viewer\n",
    "for track_id_to_plot in track_df_dict.keys():\n",
    "    \n",
    "    label = track_df_dict[track_id_to_plot].iloc[0].label   \n",
    "\n",
    "    track_df_napari = track_df_dict[track_id_to_plot][['track_id','frame','pos_y','pos_x']].copy()\n",
    "    features_df_napari = track_df_dict[track_id_to_plot][['frame','confidence','area','eccentricity','orientation','solidity']].copy()\n",
    "\n",
    "    check_continuous = np.all(np.diff(track_df_napari['frame']) == 1)   \n",
    "    if not check_continuous:\n",
    "        print(\"Frames are not continuous ... interpolating\")\n",
    "        complete_tracking   = pd.DataFrame({'frame': range(int(min_frame), int(max_frame))})\n",
    "        complete_features   = pd.DataFrame({'frame': range(int(min_frame), int(max_frame))})\n",
    "        # Merge with existing data to identify missing frames\n",
    "        merged_df_tracking = complete_tracking.merge(track_df_napari, on='frame', how='left')\n",
    "        merged_df_tracking['track_id'] = track_id_to_plot\n",
    "        merged_df_features = complete_features.merge(features_df_napari, on='frame', how='left')\n",
    "        merged_df_features.fillna(0, inplace=True)\n",
    "        # Make sure frame and track_id are the right types for interpolation\n",
    "        merged_df_tracking['frame'] = merged_df_tracking['frame'].astype(int)\n",
    "        merged_df_tracking['track_id'] = merged_df_tracking['track_id'].astype(int)\n",
    "\n",
    "        # Interpolate the position columns\n",
    "        pos_cols = ['pos_x', 'pos_y']\n",
    "        for col in pos_cols:\n",
    "            merged_df_tracking[col] = merged_df_tracking[col].interpolate(method='linear')\n",
    "\n",
    "        # # For any remaining NaN values at the start or end, use forward/backward fill\n",
    "        merged_df_tracking = merged_df_tracking.ffill()\n",
    "        merged_df_tracking = merged_df_tracking.bfill()\n",
    "        \n",
    "        track_df_napari = merged_df_tracking.copy()\n",
    "        features_df_napari = merged_df_features.copy()\n",
    "        \n",
    "    # Smooth the positions\n",
    "    pos_cols = ['pos_x', 'pos_y']\n",
    "    for col in pos_cols:\n",
    "        track_df_napari[col] = gaussian_filter1d(track_df_napari[col], sigma=sigmal_tracking_pos)\n",
    "        \n",
    "    for col in features_df_napari.columns:\n",
    "        features_df_napari[col] = features_df_napari[col].astype(float)\n",
    "    features_dict = features_df_napari.to_dict(orient='list')\n",
    "    viewer.add_tracks(track_df_napari.values, \n",
    "                      features=features_dict,\n",
    "                       name=f'{label} - id {track_id_to_plot}', \n",
    "                      colormap='hsv',\n",
    "                )\n",
    "    viewer.layers[f'{label} - id {track_id_to_plot}'].tail_width = 5\n",
    "    viewer.layers[f'{label} - id {track_id_to_plot}'].tail_length = 50\n",
    "    viewer.layers[f'{label} - id {track_id_to_plot}'].color_by = 'frame'\n",
    "    # Add masks\n",
    "    mask_zarr = root[f'{track_id_to_plot}_masks']\n",
    "    labels_layer = viewer.add_labels(\n",
    "        mask_zarr,\n",
    "        name=f'{label} - MASKS - id {track_id_to_plot}',  \n",
    "        opacity=0.1,\n",
    "        blending='additive',  \n",
    "        colormap=color_dict[track_id_to_plot], \n",
    "    )\n",
    "    \n",
    "    viewer.layers[f'{label} - id {track_id_to_plot}'].tail_width = 4\n",
    "    viewer.layers[f'{label} - id {track_id_to_plot}'].tail_length = 50"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "sam2",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

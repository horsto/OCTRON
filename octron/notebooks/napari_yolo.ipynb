{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "source": [
    "### Yolo11 tests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os , sys\n",
    "import json\n",
    "from tqdm.auto import tqdm  \n",
    "sys.path.append('..')\n",
    "from pathlib import Path\n",
    "cur_path = Path(os.getcwd()).parent\n",
    "sam2_path = cur_path / 'sam2_octron'\n",
    "sys.path.append(cur_path.as_posix())\n",
    "from matplotlib import pyplot as plt\n",
    "import cmasher as cmr\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "sns.set_theme(style='white')\n",
    "%config InlineBackend.figure_format = 'retina'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Object organizer\n",
    "# #### Importing additional stuff \n",
    "# from skimage import measure\n",
    "# from skimage.draw import polygon2mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from napari_pyav._reader import FastVideoReader\n",
    "from octron.sam2_octron.helpers.video_loader import probe_video\n",
    "from octron.yolo_octron.helpers.training import load_object_organizer, collect_labels, draw_polygons"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from ultralytics import YOLO\n",
    "from ultralytics import settings\n",
    "settings.update({'sync': False,'hub':False, })"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "settings.update({'datasets_dir': '','weights_dir':'', 'runs_dir':'OCTRON RUNS'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "File: /Users/horst/Downloads/octron_project/first_half.mp4\n",
      "Codec: h264\n",
      "Resolution: 1000 x 1000\n",
      "Frame Rate: 7\n",
      "Number of frames: 2036\n",
      "Duration: 290.86 seconds\n"
     ]
    }
   ],
   "source": [
    "# Presaved model (YOLOv11)\n",
    "path_to_model = Path('/Users/horst/Documents/python/OCTRON/octron/yolo_octron/yolo11l-seg.pt')\n",
    "# Output data from annotation in OCTRON\n",
    "path_to_json_organizer = Path('/Users/horst/Downloads/octron_project/object_organizer.json')\n",
    "# Video\n",
    "path_to_video = Path('/Users/horst/Downloads/octron_project/first_half.mp4')\n",
    "\n",
    "# Training data path \n",
    "path_to_training_root = path_to_json_organizer.parent / 'train_data'\n",
    "path_to_training_root.mkdir(exist_ok=True)\n",
    "# .. create sub dirs for training, validation and testing data\n",
    "path_to_training = path_to_training_root / 'train'\n",
    "path_to_validation = path_to_training_root / 'validation'\n",
    "path_to_testing = path_to_training_root / 'test'\n",
    "path_to_training.mkdir(exist_ok=True)\n",
    "path_to_validation.mkdir(exist_ok=True)\n",
    "path_to_testing.mkdir(exist_ok=True)\n",
    "\n",
    "# Video reader \n",
    "video_dict = probe_video(path_to_video)\n",
    "video_data = FastVideoReader(path_to_video)  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Process training data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ðŸ“– Octron object organizer loaded from /Users/horst/Downloads/octron_project/object_organizer.json\n",
      "Label wormsy has 228 annotated frames\n",
      "Label handle has 174 annotated frames\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Polygons for label wormsy: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 228/228 [00:02<00:00, 107.20it/s]\n",
      "Polygons for label handle: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 174/174 [00:03<00:00, 53.74it/s]\n"
     ]
    }
   ],
   "source": [
    "organizer_dict = load_object_organizer(path_to_json_organizer)  \n",
    "assert organizer_dict is not None\n",
    "labels = collect_labels(organizer_dict,\n",
    "                        expected_num_frames=video_dict['num_frames'],\n",
    "                        expected_image_height=video_dict['height'],\n",
    "                        expected_image_width=video_dict['width'],\n",
    "                        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "#draw_polygons(labels, video_data, 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Perform the split of the data\n",
    "# .. 80% training, 10% validation and 10% testing\n",
    "for label_id, label in labels.items():\n",
    "    break\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "label_id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'wormsy'"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "label['label']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "#model = YOLO(path_to_model)  # load a pretrained model (recommended for training)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Train/val/test sets as \n",
    "# 1) dir: path/to/imgs, \n",
    "# 2) file: path/to/imgs.txt, or list: [path/to/imgs1, path/to/imgs2, ..]\n",
    "# path: ../datasets/coco8-seg # dataset root dir (absolute or relative; if relative, it's relative to default datasets_dir)\n",
    "# train: images/train # train images (relative to 'path') 4 images\n",
    "# val: images/val # val images (relative to 'path') 4 images\n",
    "# test: # test images (optional)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "sam2",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

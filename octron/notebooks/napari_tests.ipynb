{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "source": [
    "### Napari tests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os , sys\n",
    "sys.path.append('..')\n",
    "from pathlib import Path\n",
    "cur_path = Path(os.getcwd()).parent\n",
    "\n",
    "from matplotlib import pyplot as plt\n",
    "import cmasher as cmr\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "sns.set_theme(style='white')\n",
    "%config InlineBackend.figure_format = 'retina'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import napari\n",
    "import zarr\n",
    "import shutil"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "viewer = napari.Viewer()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Initiate the SAM2 model like you do in Napari"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.environ[\"PYTORCH_ENABLE_MPS_FALLBACK\"] = \"1\"\n",
    "import torch\n",
    "from octron.sam2_octron.helpers.build_sam2_octron import build_sam2_octron"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sam2_folder = Path('sam2_octron')\n",
    "checkpoint = 'sam2.1_hiera_base_plus.pt' # under folder /checkpoints\n",
    "model_cfg = 'sam2.1/sam2.1_hiera_b+.yaml' # under folder /configs\n",
    "# ------------------------------------------------------------------------------------\n",
    "sam2_checkpoint = cur_path / sam2_folder / Path(f'checkpoints/{checkpoint}')\n",
    "model_cfg = Path(f'configs/{model_cfg}')\n",
    "\n",
    "\n",
    "predictor, device  = build_sam2_octron(config_file=model_cfg.as_posix(), \n",
    "                                                       ckpt_path=sam2_checkpoint.as_posix(), \n",
    "                                     )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### From napari, after loading video file, extract info "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "viewer.dims.set_point(0,0)\n",
    "current_indices = viewer.dims.current_step\n",
    "print(current_indices)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "video_data = viewer.layers[0].data   # the whole video\n",
    "\n",
    "print(f'video shape: {video_data.shape}')   \n",
    "num_frames, height, width, channels = video_data.shape\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_new_pred(frame_idx,\n",
    "                 obj_id, \n",
    "                 label,\n",
    "                 point):\n",
    "    assert label in [0,1]\n",
    "    # Run prediction\n",
    "    #obj_id : give a unique id to each object we interact with (it can be any integers)\n",
    "    _, out_obj_ids, out_mask_logits = predictor.add_new_points_or_box(\n",
    "                                                frame_idx=frame_idx,\n",
    "                                                obj_id=obj_id,\n",
    "                                                points=np.array([point],dtype=np.float32),\n",
    "                                                labels=np.array([label], np.int32)\n",
    "                                                )\n",
    "    \n",
    "    # Add the mask image as a new labels layer\n",
    "    mask = (out_mask_logits[0] > 0).cpu().numpy().astype(np.uint8)\n",
    "    current_label = obj_id+1\n",
    "    if len(np.unique(mask))>1:\n",
    "        mask[mask==np.unique(mask)[1]] = current_label \n",
    "    mask = mask.squeeze()\n",
    "    return mask "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create zarr store to save all resized images \n",
    "chunk_size = 8\n",
    "# Create temp output dir \n",
    "sample_dir = cur_path / 'sample_data'\n",
    "sample_dir.mkdir(exist_ok=True)\n",
    "sample_data_zarr = sample_dir / 'sample_data.zarr'\n",
    "if sample_data_zarr.exists():\n",
    "    shutil.rmtree(sample_data_zarr)\n",
    "\n",
    "# Assuming local store on fast SSD, so no compression employed for now \n",
    "store = zarr.storage.LocalStore(sample_data_zarr, read_only=False)\n",
    "root = zarr.create_group(store=store)\n",
    "image_zarr = root.create_array(name='masks',\n",
    "                                shape=(num_frames, 3, predictor.image_size, predictor.image_size),  \n",
    "                                chunks=(chunk_size, 3, predictor.image_size, predictor.image_size), \n",
    "                                shards=(chunk_size*10, 3, predictor.image_size, predictor.image_size), \n",
    "                                fill_value=np.nan,\n",
    "                                dtype='float32')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictor.init_state(napari_viewer=viewer, video_layer_idx=0, zarr_store=image_zarr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictor.reset_state()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# obj_id = 0\n",
    "\n",
    "# @thread_worker\n",
    "# def thread_predict(inference_state, frame_idx, max_imgs):\n",
    "#     global labels_layer\n",
    "#     video_segments = {} \n",
    "#     for out_frame_idx, out_obj_ids, out_mask_logits in predictor.propagate_in_video(0, max_imgs):\n",
    "#         video_segments[out_frame_idx] = {\n",
    "#                                             out_obj_id: (out_mask_logits[i] > 0.0).cpu().numpy()\n",
    "#                                             for i, out_obj_id in enumerate(out_obj_ids)\n",
    "#                                         }\n",
    "#         #  Add the mask image as a new labels layer\n",
    "#         mask = video_segments[out_frame_idx][obj_id] # THIS NEEDS TO BE MADE LAYER SPECIFIC \n",
    "#         current_label = obj_id+1\n",
    "#         if len(np.unique(mask))>1:\n",
    "#             mask[mask==np.unique(mask)[1]] = current_label \n",
    "#         mask = mask.squeeze()\n",
    "#         labels_layer.data[out_frame_idx,:,:]= mask\n",
    "#         labels_layer.refresh()   \n",
    "#         viewer.dims.set_point(0,out_frame_idx)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Instantiate the mask and annotation layers \n",
    "# Keep them empty at start \n",
    "mask_layer_dummy = np.zeros((num_frames, height, width), dtype=np.uint8)\n",
    "mask_layer_dummy.shape\n",
    "\n",
    "colors = cmr.take_cmap_colors('cmr.tropical', 8, cmap_range=(0, 1),\n",
    "                     return_fmt='int')\n",
    "colors_norm = np.stack(colors) / 255.0  \n",
    "cyclic_map = napari.utils.CyclicLabelColormap(\n",
    "    np.hstack([np.stack(colors_norm), np.ones((len(colors), 1))])\n",
    ")\n",
    "labels_layer = viewer.add_labels(\n",
    "    mask_layer_dummy, \n",
    "    name='Mask',  # Name of the layer\n",
    "    opacity=0.4,  # Optional: opacity of the labels\n",
    "    colormap=cyclic_map,\n",
    "    blending='additive'  # Optional: blending mode\n",
    ")\n",
    "# Add the points layer to the viewer\n",
    "points_layer = viewer.add_points(None, \n",
    "                                 ndim=3,\n",
    "                                 name='Annotations', \n",
    "                                 scale=(1,1),\n",
    "                                 size=40,\n",
    "                                 border_color='dimgrey',\n",
    "                                 border_width=.2,\n",
    "                                 opacity=.6,\n",
    "                                 )\n",
    "# Store the initial length of the points data\n",
    "previous_length = len(points_layer.data)\n",
    "\n",
    "\n",
    "left_right_click = 'left'\n",
    "def on_mouse_press(layer, event):\n",
    "    '''\n",
    "    Generic function to catch left and right mouse clicks\n",
    "    '''\n",
    "    global left_right_click\n",
    "    if event.type == 'mouse_press':\n",
    "        if event.button == 1:  # Left-click\n",
    "            left_right_click = 'left'\n",
    "        elif event.button == 2:  # Right-click\n",
    "            left_right_click = 'right'\n",
    "\n",
    "\n",
    "def on_points_added(event):\n",
    "\n",
    "    global points_layer\n",
    "    global labels_layer\n",
    "    global left_right_click\n",
    "    \n",
    "    global previous_length\n",
    "    global inference_state\n",
    "    \n",
    "    current_length = len(points_layer.data)\n",
    "    if current_length > previous_length:\n",
    "        previous_length = current_length \n",
    "\n",
    "        # # Execute prediction \n",
    "        newest_point_data =  points_layer.data[-1]\n",
    "        print(f'{left_right_click} click at {newest_point_data}')\n",
    "        if left_right_click == 'left':\n",
    "            label = 1\n",
    "            points_layer.face_color[-1] = [0.59607846, 0.98431373, 0.59607846, 1.]\n",
    "            points_layer.symbol[-1] = 'o'\n",
    "        elif left_right_click == 'right':\n",
    "            label = 0\n",
    "            points_layer.face_color[-1] = [1., 1., 1., 1.]\n",
    "            points_layer.symbol[-1] = 'x'\n",
    "        points_layer.refresh() \n",
    "        # Run prediction\n",
    "        frame_idx  = int(newest_point_data[0])\n",
    "        point_data = newest_point_data[1:][::-1]\n",
    "        print(f\"New point added on frame {frame_idx} at {point_data}\")  \n",
    "        mask = run_new_pred(frame_idx=frame_idx,\n",
    "                            obj_id=0,\n",
    "                            label=label,\n",
    "                            point=point_data,\n",
    "                            )\n",
    "        \n",
    "        labels_layer.data[frame_idx,:,:]= mask\n",
    "        labels_layer.refresh()   \n",
    "\n",
    "points_layer.mouse_drag_callbacks.append(on_mouse_press)\n",
    "points_layer.events.data.connect(on_points_added)\n",
    "\n",
    "# Hide the transform, delete, and select buttons\n",
    "qctrl = viewer.window.qt_viewer.controls.widgets[points_layer]\n",
    "getattr(qctrl, 'transform_button').setVisible(False)\n",
    "getattr(qctrl, 'delete_button').setVisible(False)\n",
    "getattr(qctrl, 'select_button').setVisible(False)\n",
    "# Select the current, add tool for the points layer\n",
    "viewer.layers.selection.active = points_layer\n",
    "viewer.layers.selection.active.mode = 'add'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "from napari.qt.threading import thread_worker\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "obj_id = 0\n",
    "\n",
    "\n",
    "@thread_worker()\n",
    "def thread_predict(frame_idx, max_imgs):\n",
    "    global labels_layer\n",
    "    video_segments = {} \n",
    "    for out_frame_idx, out_obj_ids, out_mask_logits in predictor.propagate_in_video(start_frame_idx=frame_idx, \n",
    "                                                                                    max_frame_num_to_track=max_imgs):\n",
    "        video_segments[out_frame_idx] = {\n",
    "                                            out_obj_id: (out_mask_logits[i] > 0.0).cpu().numpy()\n",
    "                                            for i, out_obj_id in enumerate(out_obj_ids)\n",
    "                                        }\n",
    "        #  Add the mask image as a new labels layer\n",
    "        mask = video_segments[out_frame_idx][obj_id] # THIS NEEDS TO BE MADE LAYER SPECIFIC \n",
    "        current_label = obj_id+1\n",
    "        if len(np.unique(mask))>1:\n",
    "            mask[mask==np.unique(mask)[1]] = current_label \n",
    "        mask = mask.squeeze()\n",
    "        labels_layer.data[out_frame_idx,:,:]= mask\n",
    "        viewer.dims.set_point(0,out_frame_idx)\n",
    "        labels_layer.refresh()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "worker = thread_predict(frame_idx=viewer.dims.current_step[0] , max_imgs=15)  # create \"worker\" object\n",
    "#worker.returned.connect(viewer.add_image)  # connect callback functions\n",
    "worker.start()  # start the thread!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# output_dict_per_obj is huge \n",
    "# Structure\n",
    "# -> obj_id\n",
    "# --> cond_frame_outputs\n",
    "# --> non_cond_frame_outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "worker.quit()  # stop the thread"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "sam2",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

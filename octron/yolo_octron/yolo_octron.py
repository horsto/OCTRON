# Main YOLO Octron class
# We are using YOLO11 as the base class for YOLO Octron.
# See also: https://docs.ultralytics.com/models/yolo11

from pathlib import Path
from octron.yolo_octron.helpers.training import (
    collect_labels,
    collect_polygons,
    train_test_val,
    write_training_data,
    write_yolo_config_yaml
)

class YOLO_octron:
    """
    YOLO11 segmentation model class for training with OCTRON data.
    
    This class encapsulates the full pipeline for preparing annotation data from OCTRON,
    generating training datasets, and training YOLO11 models for segmentation tasks.
    """
    
    def __init__(self, project_path, model_path):
        """
        Initialize YOLO_octron with project and model paths.
        
        Parameters
        ----------
        project_path : str or Path
            Path to the OCTRON project directory
        model_path : str or Path, optional
            Path to a pretrained YOLO11 model. 
            
        """
        try:
            from ultralytics import settings
            self.yolo_settings = settings
        except ImportError:
            raise ImportError("YOLOv11 is required to run this class.")
        
        self.project_path = Path(project_path)
        if not self.project_path.exists():
            raise FileNotFoundError(f"Project path not found: {self.project_path}")
        
        if model_path is not None:
            self.model_path = Path(model_path)
            if not self.model_path.exists():
                raise FileNotFoundError(f"Model not found at {self.model_path}")
    
        # Setup paths
        self.training_path = self.project_path / 'model' # Path to all model output
        self.data_path = self.training_path / 'training_data' # Path to training data
        
        # Initialize model to None (will be loaded when needed)
        self.model = None
        self.label_dict = None
        self.config_path = None
        
        print(f"YOLO Octron initialized with project: '{self.project_path.as_posix()}'")
        print(f"Model path: '{self.model_path.as_posix()}'")    
    
    
    def prepare_labels(self, 
                       prune_empty_labels=True, 
                       min_num_frames=10, 
                       verbose=False, 
                       ):
        """ 
        Using collect_labels(), this function finds all object organizer 
        .json files from OCTRON and parses them to extract labels.
        """
        
        self.label_dict = collect_labels(self.project_path, 
                                         prune_empty_labels=prune_empty_labels, 
                                         min_num_frames=min_num_frames, 
                                         verbose=verbose
                                        )    
        if verbose: print(f"Found {len(self.label_dict)} organizer files")
    
    def prepare_polygons(self):
        """
        Using collect_polygons(), this function extracts polygons from the
        masks/labels generated by self.prepare_labels().
        """
        if self.label_dict is None:
            raise ValueError("No labels found. Please run prepare_labels() first.")
        
        self.label_dict = collect_polygons(self.label_dict) 
            
    
    def prepare_split(self,
                      training_fraction=0.7,
                      validation_fraction=0.15,
                      verbose=False,
                     ):
        """
        Using train_test_val(), this function splits the data into training,
        testing, and validation sets.   
        """
        if self.label_dict is None:
            raise ValueError("No labels found. Please run prepare_labels() first.")
        
        for labels in self.label_dict.values():
            for entry in labels:
                if entry == 'video':
                    continue    
                # label = labels[entry]['label']
                frames = labels[entry]['frames']   
                split_dict = train_test_val(frames, 
                                            training_fraction=training_fraction,
                                            validation_fraction=validation_fraction,
                                            verbose=verbose,
                                            )

                labels[entry]['frames_split'] = split_dict
        
    
    def create_training_data(self):
        """
        Using write_training_data(), this function writes the training data
        to the training_data directory.
        """
        if self.label_dict is None:
            raise ValueError("No labels found. Please run prepare_labels() first.")
        
        # Completeness checks
        for labels in self.label_dict.values(): 
            for entry in labels:
                if entry == 'video':
                    continue
                assert 'frames' in labels[entry], "No frame indices (frames) found in labels"
                assert 'polygons' in labels[entry], "No polygons found in labels, run prepare_polygons() first"
                assert 'frames_split' in labels[entry], "No data split found in labels, run prepare_split() first"  

        # Folder checks
        try:
            self.training_path.mkdir(exist_ok=False)
        except FileExistsError as e:
            # Check if path_to_training_data is empty
            if len(list(self.training_path.glob('*'))) > 1:
                raise FileExistsError(
                    f'"{self.training_path.as_posix()}" is not empty. Please remove subfolders first.'
                    )
            else:
                pass

        write_training_data(self.label_dict, self.data_path, verbose=True)
    
    
    
    def write_yolo_config(self,
                         train_path="train",
                         val_path="val",
                         test_path="test",
                        ):
        """
        Write the YOLO configuration file for training.
        
        Parameters
        ----------
        train_path : str
            Path to training data (subfolder of self.data_path)
        val_path : str
            Path to validation data (subfolder of self.data_path)
        test_path : str
            Path to test data (subfolder of self.data_path)
            
        """
        if self.label_dict is None:
            raise ValueError("No labels found.")
        
        dataset_path = self.data_path
        if len(list(dataset_path.glob('*'))) <= 1:
            raise FileNotFoundError(
                f"No training data found in {dataset_path.as_posix()}. Please run create_training_data() first."
                )
        if (not (dataset_path / "train").exists() 
            or not (dataset_path / "val").exists() 
            or not (dataset_path / "test").exists()
            ):
            raise FileNotFoundError(
                f"Training data not found(train/val/test). Please run create_training_data() first."
                )   
        
        # Get label names from the object organizer
        label_id_label_dict = {}
        for labels in self.label_dict.values():
            for entry in labels:
                if entry == 'video':
                    continue   
                if entry in label_id_label_dict:
                    assert label_id_label_dict[entry] == labels[entry]['label'],\
                        f"Label mismatch for {entry}: {label_id_label_dict[entry]} vs {labels[entry]['label']}"
                else:
                    label_id_label_dict[entry] = labels[entry]['label']

        # Write the YAML config
        self.config_path = self.data_path / "yolo_config.yaml"
        _ = write_yolo_config_yaml(
            output_path = self.config_path,
            dataset_path = dataset_path,
            train_path = train_path,
            val_path = val_path,
            test_path = test_path,
            label_dict = label_id_label_dict,
        )
        
    
    
    def load_model(self, model_path=None):
        """
        Load the YOLO model
        
        Parameters
        ----------
        model_path : str or Path, optional
            Path to a custom model to load. If None, uses the initialized model path.
        
        Returns
        -------
        model : YOLO
            Loaded YOLO model
        """
         
        # Configure YOLO settings
        self.yolo_settings.update({
            'sync': False,
            'hub': False,
            'runs_dir': self.training_path.as_posix()
        })
        from ultralytics import YOLO   
        
        # Load specified model
        model_path = model_path if model_path else self.model_path
        self.model = YOLO(model_path)
        print(f"Model loaded from {model_path}")
        
        return self.model
    

    
    def train(self, 
              device='cpu',
              epochs=30, 
              ):
        """
        Train the YOLO model
        
        Parameters
        ----------
        device : str
            Device to use for training (i.e. "cpu", "mps" or "cuda")
            CAREFUL: There are still issues in pytorch for MPS,
            so it is recommended to use "cpu" for now.
        epochs : int
            Number of epochs to train for
      
        Returns
        -------
        results : dict
            Training results
        """
        if self.model is None:
            self.load_model()
            
        if self.config_path is None or not self.config_path.exists():
            raise FileNotFoundError(
                "No configuration yaml file found."
            )
        if device not in ['cpu', 'cuda', 'mps']:
            raise ValueError(f"Invalid device: {device}")   
        if device == 'mps':
            print("âš  MPS is not yet fully supported in PyTorch. Use at your own risk.")
            
        # Setup callbacks
        self.num_epochs = epochs
        # Start training
        print(f"Starting training for {epochs} epochs...")
        results = self.model.train(
                      data=self.config_path, 
                      save_dir=self.training_path.as_posix(),
                      name='training',
                      mode='segment',
                      device=device,
                      mask_ratio=4,
                      epochs=self.num_epochs,
                      imgsz=640,
                      resume=False,
                      plots=True,
                      batch=.9,
                      cache=False,
                      save=True,
                      save_period=15,
                      project=None,
                      exist_ok=True,
                      # augmentation
                      augment=True,
                      hsv_v=.25,
                      degrees=180,
                      scale=.5,
                      shear=2,
                      flipud=.1,
                      fliplr=.1,
                      mosaic=1.0,
                      copy_paste=.5,
                      copy_paste_mode='mixup', 
                      erasing=.25,
                      crop_fraction=1.0,
                      )
        
        print("Training complete!")
        return results
    
    def validate(self, data=None, device='auto', plots=True):
        """
        Validate the model
        
        Parameters
        ----------
        data : str or Path, optional
            Path to validation data, defaults to the validation set in the config
        device : str
            Device to use for inference
        plots : bool
            Whether to generate plots
            
        Returns
        -------
        metrics : dict
            Validation metrics
        """
        # TODO: Which model to validate
        
        # if self.model is None:
        #     self.load_model()
            
        # data_path = data if data else self.config_path
        # print(f"Running validation on {data_path}...")
        
        # metrics = self.model.val(data=data_path, device=device, plots=plots)
        
        # print("Validation results:")
        # print(f"Mean Average Precision for boxes: {metrics.box.map}")
        # print(f"Mean Average Precision for masks: {metrics.seg.map}")
        
        return metrics
    
    def predict(self):
        # # Run inference on 'bus.jpg' with arguments
        # model.predict('/Users/horst/Downloads/octron_project/test data/8_behaviour_filtered2024-11-04T14_20_34_20240930_Th19.mp4', 
        #               save=True, 
        #               classes=[0],
        #               imgsz=1000, 
        #               device='cpu',
        #               visualize=False,
        #               conf=0.9
        #               )
        pass